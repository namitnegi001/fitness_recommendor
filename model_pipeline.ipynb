{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1709c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 30000\n",
    "\n",
    "ages = np.random.randint(18, 60, size=n_samples)\n",
    "genders = np.random.choice(['Male', 'Female', 'Other'], size=n_samples)\n",
    "goals = np.random.choice(['Weight Loss', 'Muscle Gain', 'Flexibility', 'General Fitness', 'Stress Relief'], size=n_samples)\n",
    "experiences = np.random.choice(['Beginner', 'Intermediate', 'Advanced'], size=n_samples)\n",
    "hours = np.random.randint(1, 15, size=n_samples)\n",
    "workout_types = np.random.choice(['Zumba', 'Yoga', 'HIIT', 'Mix'], size=n_samples)\n",
    "timings = np.random.choice(['Morning', 'Evening', 'Flexible'], size=n_samples)\n",
    "budgets = np.random.choice(['Low', 'Medium', 'High'], size=n_samples)\n",
    "\n",
    "# Logic to assign Recommended Plan\n",
    "plans = []\n",
    "for i in range(n_samples):\n",
    "    if experiences[i] == 'Beginner' and hours[i] <= 4:\n",
    "        plans.append('Monthly')\n",
    "    elif budgets[i] == 'High' and experiences[i] == 'Advanced' and hours[i] >= 8:\n",
    "        plans.append('Yearly')\n",
    "    elif budgets[i] == 'Medium' and 4 < hours[i] < 8:\n",
    "        plans.append('Quarterly')\n",
    "    else:\n",
    "        plans.append(np.random.choice(['Monthly', 'Quarterly', 'Yearly']))\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Age': ages,\n",
    "    'Gender': genders,\n",
    "    'Fitness Goal': goals,\n",
    "    'Workout Experience': experiences,\n",
    "    'Hours/Week': hours,\n",
    "    'Workout Type': workout_types,\n",
    "    'Timing': timings,\n",
    "    'Budget': budgets,\n",
    "    'Recommended Plan': plans\n",
    "})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb9bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = data.drop('Recommended Plan', axis=1)\n",
    "y = data['Recommended Plan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eeb2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = ['Age', 'Hours/Week']\n",
    "categorical_ordinal_features = ['Workout Experience', 'Budget']\n",
    "categorical_nominal_features = ['Gender', 'Fitness Goal', 'Workout Type', 'Timing']\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('ordinal', OrdinalEncoder(categories=[['Beginner', 'Intermediate', 'Advanced'], ['Low', 'Medium', 'High']]))\n",
    "])\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_features),\n",
    "    ('ord', ordinal_pipeline, categorical_ordinal_features),\n",
    "    ('nom', nominal_pipeline, categorical_nominal_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb459d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AgeGroup'] = pd.cut(data['Age'], bins=[17, 25, 35, 45, 60], labels=['18-25', '26-35', '36-45', '46-60'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d927f04c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      2\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_selection\u001b[39m\u001b[38;5;124m'\u001b[39m, SelectKBest(score_func\u001b[38;5;241m=\u001b[39mf_classif, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)),\n\u001b[0;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=13)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "# Train\n",
    "pipe.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'feature_selection__k': [10, 13, 15],\n",
    "    'classifier__n_estimators': randint(100, 300),\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': randint(2, 10),\n",
    "    'classifier__min_samples_leaf': randint(1, 5)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e327bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "# Use best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Best Parameters Found by RandomizedSearchCV:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "print(\"\\nAccuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: SHAP Explanation\n",
    "import shap\n",
    "\n",
    "# Use the *best trained* classifier from the fitted pipeline\n",
    "# The fitted model is random_search.best_estimator_\n",
    "best_classifier = random_search.best_estimator_.named_steps['classifier']\n",
    "\n",
    "# Transform the X_test data using the preprocessor from the best fitted pipeline\n",
    "X_test_transformed = random_search.best_estimator_.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "\n",
    "# Initialize SHAP explainer for tree-based model\n",
    "explainer = shap.TreeExplainer(best_classifier)\n",
    "# shap_values = explainer.shap_values(X_test_transformed) # This will return a list of arrays for multi-class classification\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "\n",
    "# STEP 5: SHAP Plots\n",
    "# For multi-class classification, shap_values is a list.\n",
    "# We can plot the SHAP values for a specific class, e.g., class 0\n",
    "# Or plot summary for all classes (will average across classes or require specifying class)\n",
    "# Let's plot the summary plot for all classes which is common\n",
    "shap.summary_plot(shap_values, X_test_transformed, plot_type=\"bar\")\n",
    "# For the dot plot, it often looks better if we plot for a specific class\n",
    "# Let's choose class 0 for demonstration, but you might want to iterate or choose based on context\n",
    "shap.summary_plot(shap_values, X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e347d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(pipe, 'best_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0debed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_plan(input_dict):\n",
    "    \"\"\"\n",
    "    Predicts the recommended fitness plan based on input features.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_dict (dict): Dictionary containing input values for the following keys:\n",
    "        'Age', 'Gender', 'Fitness Goal', 'Workout Experience', 'Hours/Week',\n",
    "        'Workout Type', 'Timing', 'Budget'\n",
    "        \n",
    "    Returns:\n",
    "    - str: Predicted plan (e.g., 'Monthly', 'Quarterly', 'Yearly')\n",
    "    \"\"\"\n",
    "    input_df = pd.DataFrame([input_dict])\n",
    "    return best_model.predict(input_df)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb35310",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    'Age':45 ,\n",
    "    'Gender': 'Male',\n",
    "    'Fitness Goal': 'General Fitness',\n",
    "    'Workout Experience': 'Beginner',\n",
    "    'Hours/Week': 15,\n",
    "    'Workout Type': 'HIIT',\n",
    "    'Timing': 'Flexible',\n",
    "    'Budget': 'High'\n",
    "}\n",
    "\n",
    "print(predict_plan(sample_input))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
